# Spark 

## Spark Architecutre
1. Spark Core : Used for monitoring, scheduling and processing the task
2. Spark API (Polyglots) : Supports Java, Scala, Python and R
3. Spark SQL & Dataframes: Uses SQL queries. DF supports functional programming to solve data crunching problem
4. MLib: Used for Machine Learning
5. GraphX: Used for graphs
6. Streaming APIs: Streaming: Consume and Process a continuous stream of data
6. Cluster manager : Spark runs on Yarn, Mesos, Kubernetes, Standalone & Local
7. Distributed storage : HDFS, Amazon S3, NoSQL, RDBMS

## Advantages
1. Abstraction : Abrastracts distributed architecture and makes feel like working on single machine and executing SQL queries so underlying complexities are hide.
2. Unified processing: Can use polyglot, provides various liberaries to work for Machine Learning & GraphX
3. Ease to use: Complexities are hiden by Spark
4. Fast processing: In memory processing. 10x faster than Hadoop on disc and 100x faster on memory
5. Powerful caching: It has caching management

